{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89c4ecf3-9975-4464-9f82-05ca44c916ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Pipeline in Machine Learning is a tool (in Scikit-Learn) that lets you connect multiple data-processing steps and a model into one clean workflow.\n",
    "\n",
    "# Think of it like an assembly line:\n",
    "\n",
    "# üëâ Raw data goes in\n",
    "# üëâ Each step transforms it\n",
    "# üëâ A final model is trained on the processed data\n",
    "\n",
    "# Instead of writing long messy code for each step, a pipeline organizes everything in the correct order.\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# What is a Pipeline in ML?\n",
    "\n",
    "# A Pipeline is a sequence of steps where each step is:\n",
    "# A transformer (e.g., imputer, scaler, encoder)\n",
    "# or a final estimator (model)\n",
    "\n",
    "# Example steps:\n",
    "# Handle missing values\n",
    "# Scale features\n",
    "# One-hot encode categorical variables\n",
    "# Train a model\n",
    "\n",
    "\n",
    "# A pipeline chain is made of all these:\n",
    "# Pipeline([\n",
    "#     (\"imputer\", SimpleImputer()),\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"model\", LinearRegression())\n",
    "# ])\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Summary :\n",
    "\n",
    "# A pipeline is a structured, safe, and clean way to:\n",
    "# preprocess data\n",
    "# avoid leakage\n",
    "# maintain consistency\n",
    "# prepare data for ML models\n",
    "# run cross-validation easily\n",
    "\n",
    "# It lets you combine multiple preprocessing steps and the model itself into a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57414dc8-a8ad-46c6-b632-d0e37dfe995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# data = pd.read_csv(\"4CHP_Data.csv\")  # California housing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9618861-3987-437f-a7ff-c147e350f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"4CHP_Data.csv\")  # California housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bbc212e-ff35-4e78-b6e0-08b76c53e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income_cat\"] = pd.cut(data[\"median_income\"], bins=[0, 1.5, 3.0, 4.5, 6.0, np.inf], labels=[1, 2, 3, 4, 5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "890f8619-3ada-421d-ad0c-f8b5e6972c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "Shuffled = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in Shuffled.split(data, data[\"income_cat\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a45952c-2ab0-4270-baa3-1324439de0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing income cat column \n",
    "for set_ in (strat_train_set, strat_test_set) :\n",
    "    set_.drop (\"income_cat\", axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b33b5d80-7104-4522-a5bc-eddcaef3025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDf = strat_train_set.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c189d-74c4-49ac-97ab-4274d85018d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDf = TrainDf.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f42ae265-666d-4c6a-8d84-cd90bbe7504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12655</th>\n",
       "      <td>-121.46</td>\n",
       "      <td>38.52</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.1736</td>\n",
       "      <td>72100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15502</th>\n",
       "      <td>-117.23</td>\n",
       "      <td>33.09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>6.3373</td>\n",
       "      <td>279600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>-119.04</td>\n",
       "      <td>35.37</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>82700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14053</th>\n",
       "      <td>-117.13</td>\n",
       "      <td>32.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2.2264</td>\n",
       "      <td>112500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20496</th>\n",
       "      <td>-118.70</td>\n",
       "      <td>34.28</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3536.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>4.4964</td>\n",
       "      <td>238300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>-117.07</td>\n",
       "      <td>33.03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>5.0900</td>\n",
       "      <td>268500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>-121.42</td>\n",
       "      <td>38.51</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7901.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>4769.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>2.8139</td>\n",
       "      <td>90400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19263</th>\n",
       "      <td>-122.72</td>\n",
       "      <td>38.44</td>\n",
       "      <td>48.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>3.1797</td>\n",
       "      <td>140400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>-122.70</td>\n",
       "      <td>38.31</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3155.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4.1964</td>\n",
       "      <td>258100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19773</th>\n",
       "      <td>-122.14</td>\n",
       "      <td>39.97</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>3.1319</td>\n",
       "      <td>62700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "12655    -121.46     38.52                29.0       3873.0           797.0   \n",
       "15502    -117.23     33.09                 7.0       5320.0           855.0   \n",
       "2908     -119.04     35.37                44.0       1618.0           310.0   \n",
       "14053    -117.13     32.75                24.0       1877.0           519.0   \n",
       "20496    -118.70     34.28                27.0       3536.0           646.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "15174    -117.07     33.03                14.0       6665.0          1231.0   \n",
       "12661    -121.42     38.51                15.0       7901.0          1422.0   \n",
       "19263    -122.72     38.44                48.0        707.0           166.0   \n",
       "19140    -122.70     38.31                14.0       3155.0           580.0   \n",
       "19773    -122.14     39.97                27.0       1079.0           222.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "12655      2237.0       706.0         2.1736             72100.0  \n",
       "15502      2015.0       768.0         6.3373            279600.0  \n",
       "2908        667.0       300.0         2.8750             82700.0  \n",
       "14053       898.0       483.0         2.2264            112500.0  \n",
       "20496      1837.0       580.0         4.4964            238300.0  \n",
       "...           ...         ...            ...                 ...  \n",
       "15174      2026.0      1001.0         5.0900            268500.0  \n",
       "12661      4769.0      1418.0         2.8139             90400.0  \n",
       "19263       458.0       172.0         3.1797            140400.0  \n",
       "19140      1208.0       501.0         4.1964            258100.0  \n",
       "19773       625.0       197.0         3.1319             62700.0  \n",
       "\n",
       "[16512 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e9a6a2b9-31de-4c00-b93e-527d5bd3eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "my_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"MinMax\", MinMaxScaler(feature_range=(-1,1))),\n",
    "])\n",
    "\n",
    "\n",
    "#-----------Pipeline Syntax-----------\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     (\"step_name1\", transformer1),\n",
    "#     (\"step_name2\", transformer2),\n",
    "#     (\"model\", model)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d121b55-095c-47d7-97fa-6786ea740e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = my_pipeline.fit_transform(TrainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4aef84a4-ff6c-4320-84e9-678b08b29e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42430279,  0.27098831,  0.09803922, ..., -0.73711725,\n",
       "        -0.76914801, -0.76453293],\n",
       "       [ 0.41832669, -0.88310308, -0.76470588, ..., -0.71396565,\n",
       "        -0.19485248,  0.09113364],\n",
       "       [ 0.05776892, -0.39851222,  0.68627451, ..., -0.88872293,\n",
       "        -0.67240452, -0.72082177],\n",
       "       ...,\n",
       "       [-0.6752988 ,  0.25398512,  0.84313725, ..., -0.93651979,\n",
       "        -0.63037751, -0.48288461],\n",
       "       [-0.67131474,  0.22635494, -0.49019608, ..., -0.81366692,\n",
       "        -0.49014496,  0.00247422],\n",
       "       [-0.55976096,  0.57917109,  0.01960784, ..., -0.92718447,\n",
       "        -0.63697052, -0.80329566]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline  # it is a Numpy array, with all tranformations done in one go using pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbab3ab-cd90-4f4d-8f28-492005845e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transfromer :\n",
    "\n",
    "# A ColumnTransformer allows you to:\n",
    "# Apply one set of transformations to numerical columns\n",
    "# Apply another set to categorical columns\n",
    "# Leave some columns unchanged\n",
    "# Combine all results into one final numpy array\n",
    "# This makes preprocessing clean, organized, and scalable.\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Why do we need ColumnTransformer?\n",
    "# Because datasets often contain mixed data types:\n",
    "# Example (California Housing dataset):\n",
    "\n",
    "# Numerical columns ‚Üí\n",
    "# median_income, total_rooms, population, etc.\n",
    "\n",
    "# Categorical columns ‚Üí\n",
    "# ocean_proximity\n",
    "\n",
    "# You cannot apply:\n",
    "# StandardScaler to text\n",
    "# OneHotEncoder to numbers\n",
    "# So you need a tool that says:\n",
    "\n",
    "# üëâ ‚ÄúApply this to these columns, and that to those columns.‚Äù\n",
    "# This is exactly what ColumnTransformer does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aca1df99-1c56-4e11-ab16-77258195b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How ColumnTransformer Works  ----------EXAMPLE CODE------ONLY FOR UNDERSTANDING HERE----------\n",
    "\n",
    "# You create pipelines for each type of column:\n",
    "# 1Ô∏è‚É£ Numerical pipeline\n",
    "# (impute missing values + scale features) \n",
    "\n",
    "\n",
    "# num_pipeline = Pipeline([\n",
    "#     (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#     (\"scaler\", StandardScaler())\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c30a777-bdad-4e54-8b3e-24576d3905bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Categorical pipeline\n",
    "\n",
    "# (impute missing values + one-hot encode)\n",
    "\n",
    "# cat_pipeline = Pipeline([\n",
    "#     (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "#     (\"onehot\", OneHotEncoder())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a9a5aee-87cd-4cbf-b360-2f695c11fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Combine them using ColumnTransformer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# full_pipeline = ColumnTransformer([\n",
    "#     (\"num\", num_pipeline, numerical_columns),\n",
    "#     (\"cat\", cat_pipeline, categorical_columns)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4f87b06-4439-481f-8da8-2027d21b48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then simply:\n",
    "\n",
    "# prepared_data = full_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8eed34-fa64-4659-8cdb-39527e09b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "üß© Example Output Flow\n",
    "df (original)\n",
    "   ‚Üì\n",
    "ColumnTransformer\n",
    "   ‚Üí numerical ‚Üí impute ‚Üí scale\n",
    "   ‚Üí categorical ‚Üí impute ‚Üí one-hot encode\n",
    "   ‚Üì\n",
    "Combined transformed array\n",
    "   ‚Üì\n",
    "Model training / prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
