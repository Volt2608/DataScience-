{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261e7f55-ae22-4ac5-8580-70955a4ea071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning - Common Terminology\n",
    "# Before diving into neural networks, let's clarify \n",
    "# some common terms you'll encounter:\n",
    "\n",
    "# Perceptron\n",
    "# A perceptron is the simplest type of neural network — just one neuron. \n",
    "# It takes inputs, multiplies them by weights, adds a bias, and applies an\n",
    "# activation function to make a decision (e.g., classify 0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27087097-d91f-4a07-98bf-b7238d727484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - \n",
    "    \n",
    "# A neural network is a collection of interconnected layers of perceptrons (neurons).\n",
    "# Each layer transforms its inputs using weights, biases, and activation functions. \n",
    "# Deep neural networks have multiple hidden layers and can model complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d14db03-fe1c-4562-8592-3226ba5c9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - \n",
    "\n",
    "# These are settings we configure before training a model. They are not learned from the data. Examples include:\n",
    "# Learning rate: How much to adjust weights during training\n",
    "# Number of epochs: How many times the model sees the entire training dataset\n",
    "# Batch size: How many samples to process before updating weights\n",
    "# Number of layers or neurons: How many neurons are in each layer of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae0daf0-3802-4b26-8af3-6579cce47fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate (η) - \n",
    "\n",
    "# This controls how much we adjust the weights after each training step.\n",
    "# A learning rate that’s too high may overshoot the solution; too low may make training very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3827887-b5f1-4fb7-adbd-df4b4cffdcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - \n",
    "\n",
    "# This is the process where the model learns patterns from data by \n",
    "# updating weights based on errors between predicted and actual outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a7ac23-06e2-4501-b0f2-9266834c82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation -\n",
    "\n",
    "# Backpropagation is the algorithm used to update weights in a neural network. \n",
    "# It calculates the gradient of the loss function with respect to each weight by \n",
    "# applying the chain rule, allowing the model to learn from its mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7325460d-b1d2-4796-9c48-f62cfbeb5d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference -\n",
    "\n",
    "# Inference is when the trained model is used to make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df81be3-093b-4838-a52b-549ded99ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function -\n",
    "    \n",
    "# This function adds non-linearity to the output of neurons, helping networks model complex patterns.\n",
    "\n",
    "# Common activation functions:\n",
    "\n",
    "# ReLU: Rectified Linear Unit\n",
    "# Sigmoid: squashes output between 0 and 1\n",
    "# Tanh: squashes output between -1 and 1\n",
    "# Perceptrons typically use a step function as the activation, but modern neural nets often use ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c27bc-13eb-4c5a-b3b0-86a42a2b1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch -\n",
    "\n",
    "# One epoch means one full pass over the entire training dataset. \n",
    "# Multiple epochs are used so the model can keep refining its understanding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
